{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin1', header=None)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset.isna().sum()\nprint (dataset.values[0:1])\ndataset[0].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = dataset[5]\ny = dataset[0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\nhashtags = re.compile(r\"^#\\S+|\\s#\\S+\")\nmentions = re.compile(r\"^@\\S+|\\s@\\S+\")\nurls = re.compile(r\"https?://\\S+\")\n\ndef process_text(text):\n  text = hashtags.sub('hashtag', text)\n  text = mentions.sub('entity', text)\n  return text.strip().lower()\n  \ndef match_expr(pattern, string):\n  return not pattern.search(string) == None\n\ndef get_data_wo_urls(dataset):\n    link_with_urls = dataset.text.apply(lambda x: match_expr(urls, x))\n    return dataset[[not e for e in link_with_urls]]\n\nx=x.apply(process_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_urls (vTEXT):\n    vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n    return(vTEXT)\n\nx=x.apply(remove_urls)\nprint (x[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from gensim.parsing.preprocessing import remove_stopwords, strip_numeric, strip_punctuation, strip_short, stem_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=x.apply(remove_stopwords)\nx=x.apply(strip_numeric)\nx=x.apply(strip_punctuation)\nx=x.apply(strip_short)\nx=x.apply(stem_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.values[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=0, test_size=0.25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, SimpleRNN, Embedding, Dropout, Activation, GRU, Flatten\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model, Sequential\nfrom keras.layers import Convolution1D\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\nmax_features = 6000\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(x_train)\n\nlist_tokenized_train = tokenizer.texts_to_sequences(x_train)\nx_test = tokenizer.texts_to_sequences(x_test)\n\nmaxlen = 130\nx_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\nx_test = pad_sequences(x_test, maxlen=maxlen)\n\nembed_size = 32\nmodel = Sequential()\nmodel.add(Embedding(max_features, embed_size))\nmodel.add((SimpleRNN(32, return_sequences=False)))\nmodel.add(Dense(20, activation=\"relu\"))\nmodel.add(Dropout(0.05))\nmodel.add(Dense(1, activation=\"sigmoid\"))\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nbatch_size = 64\nepochs = 5\nhist=model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
